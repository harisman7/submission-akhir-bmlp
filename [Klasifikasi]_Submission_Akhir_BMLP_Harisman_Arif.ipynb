{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset dari hasil clustering\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/harisman7/submission-akhir-bmlp/refs/heads/main/result_df.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9da8e4-0ccf-4d0f-8b74-fbeb608db0c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Store  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price         CPI  \\\n",
            "0      1    1643690.90             0        42.31       2.572  211.096358   \n",
            "1      1    1641957.44             1        38.51       2.548  211.242170   \n",
            "2      1    1611968.17             0        39.93       2.514  211.289143   \n",
            "3      1    1409727.59             0        46.63       2.561  211.319643   \n",
            "4      1    1554806.68             0        46.50       2.625  211.350143   \n",
            "\n",
            "   Unemployment  day  month  year  Cluster  cluster  \n",
            "0         8.106    5      2  2010        0        1  \n",
            "1         8.106   12      2  2010        0        1  \n",
            "2         8.106   19      2  2010        0        1  \n",
            "3         8.106   26      2  2010        0        1  \n",
            "4         8.106    5      3  2010        0        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur dan target\n",
        "X = df.drop('cluster', axis=1)\n",
        "y = df['cluster']\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Menampilkan dimensi data\n",
        "print(f\"Dimensi X_train: {X_train.shape}\")\n",
        "print(f\"Dimensi X_test: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fd1478-620b-435d-b3c4-b402356b9957"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi X_train: (5148, 11)\n",
            "Dimensi X_test: (1287, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Melatih model dan melakukan prediksi\n",
        "predictions = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions[name] = model.predict(X_test)\n",
        "\n",
        "# Mengambil hasil prediksi\n",
        "y_pred_log_reg = predictions[\"Logistic Regression\"]\n",
        "y_pred_rf = predictions[\"Random Forest\"]\n",
        "y_pred_dt = predictions[\"Decision Tree\"]\n",
        "y_pred_svm = predictions[\"SVM\"]\n",
        "y_pred_knn = predictions[\"KNN\"]"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk evaluasi model\n",
        "def evaluate_model(y_test, y_pred, model_name):\n",
        "    print(f\"\\nEvaluasi {model_name} sebelum tuning:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluasi masing-masing model\n",
        "for name, y_pred in zip(\n",
        "    [\"Logistic Regression\", \"Random Forest\", \"Decision Tree\", \"SVM\", \"K-Nearest Neighbors\"],\n",
        "    [y_pred_log_reg, y_pred_rf, y_pred_dt, y_pred_svm, y_pred_knn]\n",
        "):\n",
        "    evaluate_model(y_test, y_pred, name)"
      ],
      "metadata": {
        "id": "tMq4QAssNLip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010ab28b-7198-44cd-c1cc-1c02d37ab053"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Logistic Regression sebelum tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi Random Forest sebelum tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi Decision Tree sebelum tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi SVM sebelum tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi K-Nearest Neighbors sebelum tuning:\n",
            "Accuracy: 0.9883\n",
            "F1-Score: 0.9884\n",
            "Confusion Matrix:\n",
            " [[437   0   3   0]\n",
            " [  4 308   0   0]\n",
            " [  8   0 324   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       440\n",
            "           1       1.00      0.99      0.99       312\n",
            "           2       0.99      0.98      0.98       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           0.99      1287\n",
            "   macro avg       0.99      0.99      0.99      1287\n",
            "weighted avg       0.99      0.99      0.99      1287\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ],
      "metadata": {
        "id": "ph9yIYDXEPuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ],
      "metadata": {
        "id": "-Bikx3LINv5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation setup\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk tuning model\n",
        "def tune_model(model, param_grid, X_train, y_train, skf):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Inisialisasi StratifiedKFold untuk cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Tuning untuk masing-masing model\n",
        "param_grid_log_reg = {'C': [0.001, 0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "best_log_reg = tune_model(LogisticRegression(random_state=42, max_iter=2000, solver='liblinear'), param_grid_log_reg, X_train, y_train, skf)\n",
        "\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
        "best_rf_clf = tune_model(RandomForestClassifier(random_state=42), param_grid_rf, X_train, y_train, skf)\n",
        "\n",
        "param_grid_dt = {'max_depth': [10, 20, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
        "best_dt_clf = tune_model(DecisionTreeClassifier(random_state=42), param_grid_dt, X_train, y_train, skf)\n",
        "\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "best_svm_clf = tune_model(SVC(random_state=42), param_grid_svm, X_train, y_train, skf)\n",
        "\n",
        "param_grid_knn = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
        "best_knn_clf = tune_model(KNeighborsClassifier(), param_grid_knn, X_train, y_train, skf)"
      ],
      "metadata": {
        "id": "HzuNP3I5wfaE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ],
      "metadata": {
        "id": "hE7pqlEPEYzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ],
      "metadata": {
        "id": "feaPESoeN0zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk evaluasi model setelah tuning\n",
        "def evaluate_tuned_model(y_test, best_model, model_name):\n",
        "    y_pred_best = best_model.predict(X_test)\n",
        "    print(f\"\\nEvaluasi {model_name} setelah tuning:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred_best, average='weighted'):.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
        "    print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "# Evaluasi model setelah tuning menggunakan loop\n",
        "models = {\n",
        "    \"Logistic Regression\": best_log_reg,\n",
        "    \"Random Forest\": best_rf_clf,\n",
        "    \"Decision Tree\": best_dt_clf,\n",
        "    \"SVM\": best_svm_clf,\n",
        "    \"K-Nearest Neighbors\": best_knn_clf\n",
        "}\n",
        "\n",
        "for model_name, best_model in models.items():\n",
        "    evaluate_tuned_model(y_test, best_model, model_name)"
      ],
      "metadata": {
        "id": "HTXZRvEeNMb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0923d29a-6f79-43b2-a3ac-21c79c3d6224"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Logistic Regression setelah tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi Random Forest setelah tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi Decision Tree setelah tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi SVM setelah tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[440   0   0   0]\n",
            " [  0 312   0   0]\n",
            " [  0   0 332   0]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       440\n",
            "           1       1.00      1.00      1.00       312\n",
            "           2       1.00      1.00      1.00       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           1.00      1287\n",
            "   macro avg       1.00      1.00      1.00      1287\n",
            "weighted avg       1.00      1.00      1.00      1287\n",
            "\n",
            "\n",
            "Evaluasi K-Nearest Neighbors setelah tuning:\n",
            "Accuracy: 0.9922\n",
            "F1-Score: 0.9922\n",
            "Confusion Matrix:\n",
            " [[439   0   1   0]\n",
            " [  2 310   0   0]\n",
            " [  5   1 325   1]\n",
            " [  0   0   0 203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       440\n",
            "           1       1.00      0.99      1.00       312\n",
            "           2       1.00      0.98      0.99       332\n",
            "           3       1.00      1.00      1.00       203\n",
            "\n",
            "    accuracy                           0.99      1287\n",
            "   macro avg       0.99      0.99      0.99      1287\n",
            "weighted avg       0.99      0.99      0.99      1287\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk cross-validation performance\n",
        "def cross_val_performance(model, X, y, skf):\n",
        "    cross_val_accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "    cross_val_f1 = cross_val_score(model, X, y, cv=skf, scoring='f1_weighted')\n",
        "    return cross_val_accuracy, cross_val_f1\n",
        "\n",
        "# Menyusun model dan nama model dalam dictionary\n",
        "models = {\n",
        "    \"Logistic Regression\": best_log_reg,\n",
        "    \"Random Forest\": best_rf_clf,\n",
        "    \"Decision Tree\": best_dt_clf,\n",
        "    \"SVM\": best_svm_clf,\n",
        "    \"K-Nearest Neighbors\": best_knn_clf\n",
        "}\n",
        "\n",
        "# Cross-validation untuk masing-masing model\n",
        "for name, model in models.items():\n",
        "    cross_val_accuracy, cross_val_f1 = cross_val_performance(model, X, y, skf)\n",
        "    print(f\"\\nCross-validation untuk {name}:\")\n",
        "    print(f\"Accuracy: {cross_val_accuracy.mean():.4f} ± {cross_val_accuracy.std():.4f}\")\n",
        "    print(f\"F1-Score: {cross_val_f1.mean():.4f} ± {cross_val_f1.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMb6RuVwwro2",
        "outputId": "a02fb41e-2f9b-4b63-c58e-43dbc477b310"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation untuk Logistic Regression:\n",
            "Accuracy: 0.9992 ± 0.0009\n",
            "F1-Score: 0.9992 ± 0.0009\n",
            "\n",
            "Cross-validation untuk Random Forest:\n",
            "Accuracy: 0.9997 ± 0.0004\n",
            "F1-Score: 0.9997 ± 0.0004\n",
            "\n",
            "Cross-validation untuk Decision Tree:\n",
            "Accuracy: 0.9998 ± 0.0003\n",
            "F1-Score: 0.9998 ± 0.0003\n",
            "\n",
            "Cross-validation untuk SVM:\n",
            "Accuracy: 0.9998 ± 0.0003\n",
            "F1-Score: 0.9998 ± 0.0003\n",
            "\n",
            "Cross-validation untuk K-Nearest Neighbors:\n",
            "Accuracy: 0.9998 ± 0.0003\n",
            "F1-Score: 0.9998 ± 0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.\n",
        "\n",
        "Berdasarkan hasil evaluasi model (Logistic Regression, Random Forest, Decision Tree, dan SVM), berikut adalah analisis dan rekomendasi tindakan lanjutan:\n",
        "#### 1. Perbandingan Hasil Evaluasi\n",
        "- **Logistic Regression**: Akurasi 0.9992, F1-Score 0.9992\n",
        "- **Random Forest**: Akurasi 0.9997, F1-Score 0.9997\n",
        "- **Decision Tree**: Akurasi 0.9998, F1-Score 0.9998\n",
        "- **SVM**: Akurasi 0.9998, F1-Score 0.9998\n",
        "\n",
        "Dari hasil ini, **Decision Tree** dan **SVM** memberikan hasil yang paling tinggi dengan akurasi dan F1-score sebesar 0.9998, yang menunjukkan bahwa keduanya bekerja sangat baik. **Random Forest** juga memberikan hasil yang sangat baik dengan akurasi 0.9997 dan F1-score 0.9997, sedangkan **Logistic Regression** memberikan hasil yang sedikit lebih rendah, tetapi tetap sangat baik dengan akurasi 0.9992 dan F1-score 0.9992.\n",
        "\n",
        "#### 2. Identifikasi Kelemahan Model\n",
        "- ### **Precision dan Recall**  \n",
        "Meskipun akurasi dan F1-Score sangat tinggi pada semua model, masalah **precision** atau **recall** rendah untuk kelas tertentu mungkin terjadi, terutama jika dataset tidak seimbang. **Logistic Regression**  meskipun menunjukkan hasil yang baik dengan akurasi 0.9992 dan F1-Score 0.9992, bisa mengalami masalah pada kelas minoritas, meskipun hal ini belum dapat dipastikan tanpa analisis lebih lanjut. Pada **Random Forest**, meskipun akurasi tinggi dengan nilai 0.9997 dan F1-Score 0.9997, model bisa lebih fokus pada kelas mayoritas, menyebabkan **precision** atau **recall** rendah pada kelas minoritas. **Decision Tree** juga berpotensi mengalami hal serupa jika dataset tidak seimbang, meskipun hasil secara keseluruhan sangat baik dengan akurasi 0.9998 dan F1-Score 0.9998. Begitu pula dengan **SVM**, yang meskipun menunjukkan hasil yang sangat baik dengan akurasi 0.9998 dan F1-Score 0.9998, dapat mengalami masalah serupa jika distribusi kelas tidak merata.\n",
        "\n",
        "- ### **Overfitting atau Underfitting**  \n",
        "Secara umum, model-model yang diuji menunjukkan hasil yang sangat tinggi, yang menandakan kemungkinan besar tidak ada **underfitting**. Namun, beberapa model, seperti **Random Forest**, **Decision Tree**, dan **SVM**, berisiko mengalami **overfitting** karena kompleksitasnya. **Random Forest** dan **Decision Tree**, yang cenderung sangat fleksibel, berpotensi menyesuaikan diri terlalu banyak dengan data pelatihan dan kurang menggeneralisasi pada data uji. **SVM**, meskipun kinerjanya sangat baik, juga bisa mengalami **overfitting** jika parameter tidak disesuaikan dengan baik.\n",
        "\n",
        "#### 3. Rekomendasi Tindakan Lanjutan\n",
        "- ### **1. Analisis Confusion Matrix**  \n",
        "Confusion matrix penting untuk memahami distribusi prediksi model, khususnya kesalahan tipe I (false positives) dan tipe II (false negatives). Analisis ini membantu menentukan prioritas antara Precision dan Recall sesuai kebutuhan aplikasi, misalnya mengurangi false negatives untuk aplikasi yang memerlukan sensitivitas tinggi.\n",
        "\n",
        "- ### **2. Validasi dengan Data Baru**  \n",
        "Validasi menggunakan **k-fold cross-validation** dan dataset terpisah (test set) memastikan performa model tidak hanya baik di data pelatihan tetapi juga dapat diandalkan di dunia nyata. Langkah ini penting untuk mengidentifikasi kemampuan generalisasi model.\n",
        "\n",
        "- ### **3. Pengurangan Overfitting**  \n",
        "Overfitting pada Decision Tree dapat diatasi dengan pruning, sedangkan Random Forest dapat dioptimalkan melalui pengaturan jumlah pohon (**n_estimators**) dan kedalaman maksimum pohon (**max_depth**). Langkah ini memastikan model tetap efisien dan tidak hanya menghafal data.\n",
        "\n",
        "- ### **4. Hyperparameter Tuning**  \n",
        "Menggunakan **Grid Search** atau **Random Search** untuk optimasi hyperparameter seperti **C** dan **gamma** pada SVM, atau kedalaman pohon pada Random Forest, membantu meningkatkan performa model. Tuning ini memastikan model dapat menangani data kompleks dengan lebih baik."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4kVc-7C8oBuy"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}