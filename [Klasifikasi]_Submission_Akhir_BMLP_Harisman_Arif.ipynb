{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset dari hasil clustering\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/harisman7/submission-akhir-bmlp/refs/heads/main/result_df.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59de91cb-c814-431e-b0ca-094a980973d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Temperature   Humidity  Wind_Speed  Cloud_Cover     Pressure  Rain  \\\n",
            "0    23.720338  89.592641    7.335604    50.501694  1032.378759     1   \n",
            "1    27.879734  46.489704    5.952484     4.990053   992.614189     0   \n",
            "2    25.069084  83.072843    1.371992    14.855784  1007.231620     0   \n",
            "3    23.622080  74.367758    7.050551    67.255282   982.632013     1   \n",
            "4    20.591370  96.858822    4.643921    47.676444   980.825142     0   \n",
            "\n",
            "   Cluster  cluster  \n",
            "0        1        2  \n",
            "1        3        0  \n",
            "2        3        0  \n",
            "3        1        1  \n",
            "4        3        2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur dan target\n",
        "X = df.drop('cluster', axis=1)\n",
        "y = df['cluster']\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Menampilkan dimensi data\n",
        "print(f\"Dimensi X_train: {X_train.shape}\")\n",
        "print(f\"Dimensi X_test: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48504921-3528-468e-ff1d-1d8bc5242726"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi X_train: (2000, 7)\n",
            "Dimensi X_test: (500, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Melatih model dan melakukan prediksi\n",
        "predictions = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions[name] = model.predict(X_test)\n",
        "\n",
        "# Mengambil hasil prediksi\n",
        "y_pred_log_reg = predictions[\"Logistic Regression\"]\n",
        "y_pred_rf = predictions[\"Random Forest\"]\n",
        "y_pred_dt = predictions[\"Decision Tree\"]\n",
        "y_pred_svm = predictions[\"SVM\"]\n",
        "y_pred_knn = predictions[\"KNN\"]"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk evaluasi model\n",
        "def evaluate_model(y_test, y_pred, model_name):\n",
        "    print(f\"\\nEvaluasi {model_name} sebelum tuning:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluasi masing-masing model\n",
        "for name, y_pred in zip(\n",
        "    [\"Logistic Regression\", \"Random Forest\", \"Decision Tree\", \"SVM\", \"K-Nearest Neighbors\"],\n",
        "    [y_pred_log_reg, y_pred_rf, y_pred_dt, y_pred_svm, y_pred_knn]\n",
        "):\n",
        "    evaluate_model(y_test, y_pred, name)"
      ],
      "metadata": {
        "id": "tMq4QAssNLip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5531b8f-f2a9-4287-a0b0-4c04bcc74a59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Logistic Regression sebelum tuning:\n",
            "Accuracy: 0.9740\n",
            "F1-Score: 0.9740\n",
            "Confusion Matrix:\n",
            " [[154   0   2   0]\n",
            " [  0 103   2   1]\n",
            " [  3   1 115   0]\n",
            " [  0   4   0 115]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       156\n",
            "           1       0.95      0.97      0.96       106\n",
            "           2       0.97      0.97      0.97       119\n",
            "           3       0.99      0.97      0.98       119\n",
            "\n",
            "    accuracy                           0.97       500\n",
            "   macro avg       0.97      0.97      0.97       500\n",
            "weighted avg       0.97      0.97      0.97       500\n",
            "\n",
            "\n",
            "Evaluasi Random Forest sebelum tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[156   0   0   0]\n",
            " [  0 106   0   0]\n",
            " [  0   0 119   0]\n",
            " [  0   0   0 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       156\n",
            "           1       1.00      1.00      1.00       106\n",
            "           2       1.00      1.00      1.00       119\n",
            "           3       1.00      1.00      1.00       119\n",
            "\n",
            "    accuracy                           1.00       500\n",
            "   macro avg       1.00      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n",
            "\n",
            "Evaluasi Decision Tree sebelum tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[156   0   0   0]\n",
            " [  0 106   0   0]\n",
            " [  0   0 119   0]\n",
            " [  0   0   0 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       156\n",
            "           1       1.00      1.00      1.00       106\n",
            "           2       1.00      1.00      1.00       119\n",
            "           3       1.00      1.00      1.00       119\n",
            "\n",
            "    accuracy                           1.00       500\n",
            "   macro avg       1.00      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n",
            "\n",
            "Evaluasi SVM sebelum tuning:\n",
            "Accuracy: 0.9380\n",
            "F1-Score: 0.9382\n",
            "Confusion Matrix:\n",
            " [[149   0   7   0]\n",
            " [  0  96   3   7]\n",
            " [  2   3 114   0]\n",
            " [  0   9   0 110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       156\n",
            "           1       0.89      0.91      0.90       106\n",
            "           2       0.92      0.96      0.94       119\n",
            "           3       0.94      0.92      0.93       119\n",
            "\n",
            "    accuracy                           0.94       500\n",
            "   macro avg       0.93      0.94      0.93       500\n",
            "weighted avg       0.94      0.94      0.94       500\n",
            "\n",
            "\n",
            "Evaluasi K-Nearest Neighbors sebelum tuning:\n",
            "Accuracy: 0.8780\n",
            "F1-Score: 0.8777\n",
            "Confusion Matrix:\n",
            " [[147   0   9   0]\n",
            " [  0  84   6  16]\n",
            " [ 10   8 101   0]\n",
            " [  0  12   0 107]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94       156\n",
            "           1       0.81      0.79      0.80       106\n",
            "           2       0.87      0.85      0.86       119\n",
            "           3       0.87      0.90      0.88       119\n",
            "\n",
            "    accuracy                           0.88       500\n",
            "   macro avg       0.87      0.87      0.87       500\n",
            "weighted avg       0.88      0.88      0.88       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ],
      "metadata": {
        "id": "ph9yIYDXEPuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ],
      "metadata": {
        "id": "-Bikx3LINv5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation setup\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk tuning model\n",
        "def tune_model(model, param_grid, X_train, y_train, skf):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Inisialisasi StratifiedKFold untuk cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Tuning untuk masing-masing model\n",
        "param_grid_log_reg = {'C': [0.001, 0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "best_log_reg = tune_model(LogisticRegression(random_state=42, max_iter=2000, solver='liblinear'), param_grid_log_reg, X_train, y_train, skf)\n",
        "\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
        "best_rf_clf = tune_model(RandomForestClassifier(random_state=42), param_grid_rf, X_train, y_train, skf)\n",
        "\n",
        "param_grid_dt = {'max_depth': [10, 20, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n",
        "best_dt_clf = tune_model(DecisionTreeClassifier(random_state=42), param_grid_dt, X_train, y_train, skf)\n",
        "\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "best_svm_clf = tune_model(SVC(random_state=42), param_grid_svm, X_train, y_train, skf)\n",
        "\n",
        "param_grid_knn = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
        "best_knn_clf = tune_model(KNeighborsClassifier(), param_grid_knn, X_train, y_train, skf)"
      ],
      "metadata": {
        "id": "HzuNP3I5wfaE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ],
      "metadata": {
        "id": "hE7pqlEPEYzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ],
      "metadata": {
        "id": "feaPESoeN0zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk evaluasi model setelah tuning\n",
        "def evaluate_tuned_model(y_test, best_model, model_name):\n",
        "    y_pred_best = best_model.predict(X_test)\n",
        "    print(f\"\\nEvaluasi {model_name} setelah tuning:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred_best, average='weighted'):.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
        "    print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "# Evaluasi model setelah tuning menggunakan loop\n",
        "models = {\n",
        "    \"Logistic Regression\": best_log_reg,\n",
        "    \"Random Forest\": best_rf_clf,\n",
        "    \"Decision Tree\": best_dt_clf,\n",
        "    \"SVM\": best_svm_clf,\n",
        "    \"K-Nearest Neighbors\": best_knn_clf\n",
        "}\n",
        "\n",
        "for model_name, best_model in models.items():\n",
        "    evaluate_tuned_model(y_test, best_model, model_name)"
      ],
      "metadata": {
        "id": "HTXZRvEeNMb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6724db-48b1-4a9e-eac7-6a4eb84111bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Logistic Regression setelah tuning:\n",
            "Accuracy: 0.9260\n",
            "F1-Score: 0.9249\n",
            "Confusion Matrix:\n",
            " [[156   0   0   0]\n",
            " [  0  80  25   1]\n",
            " [  3   8 108   0]\n",
            " [  0   0   0 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       156\n",
            "           1       0.91      0.75      0.82       106\n",
            "           2       0.81      0.91      0.86       119\n",
            "           3       0.99      1.00      1.00       119\n",
            "\n",
            "    accuracy                           0.93       500\n",
            "   macro avg       0.92      0.92      0.92       500\n",
            "weighted avg       0.93      0.93      0.92       500\n",
            "\n",
            "\n",
            "Evaluasi Random Forest setelah tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[156   0   0   0]\n",
            " [  0 106   0   0]\n",
            " [  0   0 119   0]\n",
            " [  0   0   0 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       156\n",
            "           1       1.00      1.00      1.00       106\n",
            "           2       1.00      1.00      1.00       119\n",
            "           3       1.00      1.00      1.00       119\n",
            "\n",
            "    accuracy                           1.00       500\n",
            "   macro avg       1.00      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n",
            "\n",
            "Evaluasi Decision Tree setelah tuning:\n",
            "Accuracy: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[156   0   0   0]\n",
            " [  0 106   0   0]\n",
            " [  0   0 119   0]\n",
            " [  0   0   0 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       156\n",
            "           1       1.00      1.00      1.00       106\n",
            "           2       1.00      1.00      1.00       119\n",
            "           3       1.00      1.00      1.00       119\n",
            "\n",
            "    accuracy                           1.00       500\n",
            "   macro avg       1.00      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n",
            "\n",
            "Evaluasi SVM setelah tuning:\n",
            "Accuracy: 0.9880\n",
            "F1-Score: 0.9880\n",
            "Confusion Matrix:\n",
            " [[156   0   0   0]\n",
            " [  0 105   1   0]\n",
            " [  2   0 117   0]\n",
            " [  0   3   0 116]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       156\n",
            "           1       0.97      0.99      0.98       106\n",
            "           2       0.99      0.98      0.99       119\n",
            "           3       1.00      0.97      0.99       119\n",
            "\n",
            "    accuracy                           0.99       500\n",
            "   macro avg       0.99      0.99      0.99       500\n",
            "weighted avg       0.99      0.99      0.99       500\n",
            "\n",
            "\n",
            "Evaluasi K-Nearest Neighbors setelah tuning:\n",
            "Accuracy: 0.8740\n",
            "F1-Score: 0.8741\n",
            "Confusion Matrix:\n",
            " [[147   0   9   0]\n",
            " [  0  86   5  15]\n",
            " [ 10  10  99   0]\n",
            " [  0  14   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94       156\n",
            "           1       0.78      0.81      0.80       106\n",
            "           2       0.88      0.83      0.85       119\n",
            "           3       0.88      0.88      0.88       119\n",
            "\n",
            "    accuracy                           0.87       500\n",
            "   macro avg       0.87      0.87      0.87       500\n",
            "weighted avg       0.87      0.87      0.87       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk cross-validation performance\n",
        "def cross_val_performance(model, X, y, skf):\n",
        "    cross_val_accuracy = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "    cross_val_f1 = cross_val_score(model, X, y, cv=skf, scoring='f1_weighted')\n",
        "    return cross_val_accuracy, cross_val_f1\n",
        "\n",
        "# Menyusun model dan nama model dalam dictionary\n",
        "models = {\n",
        "    \"Logistic Regression\": best_log_reg,\n",
        "    \"Random Forest\": best_rf_clf,\n",
        "    \"Decision Tree\": best_dt_clf,\n",
        "    \"SVM\": best_svm_clf,\n",
        "    \"K-Nearest Neighbors\": best_knn_clf\n",
        "}\n",
        "\n",
        "# Cross-validation untuk masing-masing model\n",
        "for name, model in models.items():\n",
        "    cross_val_accuracy, cross_val_f1 = cross_val_performance(model, X, y, skf)\n",
        "    print(f\"\\nCross-validation untuk {name}:\")\n",
        "    print(f\"Accuracy: {cross_val_accuracy.mean():.4f} ± {cross_val_accuracy.std():.4f}\")\n",
        "    print(f\"F1-Score: {cross_val_f1.mean():.4f} ± {cross_val_f1.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMb6RuVwwro2",
        "outputId": "5a885ddf-d792-468f-c4dd-dec031ee980d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation untuk Logistic Regression:\n",
            "Accuracy: 0.9008 ± 0.0102\n",
            "F1-Score: 0.8981 ± 0.0106\n",
            "\n",
            "Cross-validation untuk Random Forest:\n",
            "Accuracy: 0.9964 ± 0.0015\n",
            "F1-Score: 0.9964 ± 0.0015\n",
            "\n",
            "Cross-validation untuk Decision Tree:\n",
            "Accuracy: 0.9988 ± 0.0010\n",
            "F1-Score: 0.9988 ± 0.0010\n",
            "\n",
            "Cross-validation untuk SVM:\n",
            "Accuracy: 0.9932 ± 0.0053\n",
            "F1-Score: 0.9932 ± 0.0053\n",
            "\n",
            "Cross-validation untuk K-Nearest Neighbors:\n",
            "Accuracy: 0.9320 ± 0.0110\n",
            "F1-Score: 0.9319 ± 0.0111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.\n",
        "\n",
        "Berdasarkan hasil evaluasi model (Logistic Regression, Random Forest, Decision Tree, dan SVM), berikut adalah analisis dan rekomendasi tindakan lanjutan:\n",
        "#### 1. Perbandingan Hasil Evaluasi\n",
        "- **Logistic Regression**: Akurasi 0.9008, F1-Score 0.8981\n",
        "- **Random Forest**: Akurasi 0.9964, F1-Score 0.9964\n",
        "- **Decision Tree**: Akurasi 0.9988, F1-Score 0.9988\n",
        "- **SVM**: Akurasi 0.9932, F1-Score 0.9932\n",
        "\n",
        "Secara keseluruhan, **Random Forest** dan **Decision Tree** menunjukkan performa terbaik dengan akurasi serta F1-Score yang sangat tinggi dan konsisten. Sementara itu, **Logistic Regression** dan **SVM** juga memberikan hasil yang baik, meskipun sedikit lebih rendah.\n",
        "\n",
        "#### 2. Identifikasi Kelemahan Model\n",
        "- ### **Precision dan Recall**  \n",
        "Berdasarkan hasil evaluasi, **Logistic Regression** menunjukkan F1-Score 0.8981, yang mengindikasikan kemungkinan adanya ketidakseimbangan antara Precision dan Recall, terutama jika data memiliki karakteristik yang kompleks atau tidak linier. Pada **Random Forest** dan **Decision Tree**, F1-Score yang sangat tinggi (0.9964 dan 0.9988) menunjukkan performa Precision dan Recall yang hampir sempurna, tetapi perlu analisis lebih lanjut untuk memastikan tidak ada dominasi salah satu metrik. Sementara itu, **SVM** dengan F1-Score 0.9932 juga menunjukkan keseimbangan Precision dan Recall yang baik, meskipun performanya sedikit di bawah Random Forest dan Decision Tree, kemungkinan karena kurang optimalnya hyperparameter atau batas margin.\n",
        "\n",
        "- ### **Overfitting atau Underfitting**  \n",
        "Berdasarkan hasil evaluasi, **Logistic Regression** cenderung mengalami **underfitting**, terutama karena model ini bersifat linear dan mungkin kurang mampu menangkap pola non-linear dalam data. Sebaliknya, **Random Forest** dan **Decision Tree** memiliki risiko **overfitting** yang tinggi, terutama Decision Tree, karena model ini dapat dengan mudah menyesuaikan diri dengan data pelatihan hingga menghasilkan akurasi dan F1-Score hampir sempurna. **SVM** berada di antara kedua ekstrem ini, dengan potensi **underfitting** jika parameter seperti kernel atau margin tidak diatur dengan baik, tetapi juga dapat mengalami **overfitting** jika menangani dataset dengan jumlah fitur yang sangat besar tanpa regularisasi.\n",
        "\n",
        "#### 3. Rekomendasi Tindakan Lanjutan\n",
        "- ### **1. Analisis Confusion Matrix**  \n",
        "Confusion matrix penting untuk memahami distribusi prediksi model, khususnya kesalahan tipe I (false positives) dan tipe II (false negatives). Analisis ini membantu menentukan prioritas antara Precision dan Recall sesuai kebutuhan aplikasi, misalnya mengurangi false negatives untuk aplikasi yang memerlukan sensitivitas tinggi.\n",
        "\n",
        "- ### **2. Validasi dengan Data Baru**  \n",
        "Validasi menggunakan **k-fold cross-validation** dan dataset terpisah (test set) memastikan performa model tidak hanya baik di data pelatihan tetapi juga dapat diandalkan di dunia nyata. Langkah ini penting untuk mengidentifikasi kemampuan generalisasi model.\n",
        "\n",
        "- ### **3. Pengurangan Overfitting**  \n",
        "Overfitting pada Decision Tree dapat diatasi dengan pruning, sedangkan Random Forest dapat dioptimalkan melalui pengaturan jumlah pohon (**n_estimators**) dan kedalaman maksimum pohon (**max_depth**). Langkah ini memastikan model tetap efisien dan tidak hanya menghafal data.\n",
        "\n",
        "- ### **4. Hyperparameter Tuning**  \n",
        "Menggunakan **Grid Search** atau **Random Search** untuk optimasi hyperparameter seperti **C** dan **gamma** pada SVM, atau kedalaman pohon pada Random Forest, membantu meningkatkan performa model. Tuning ini memastikan model dapat menangani data kompleks dengan lebih baik."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    }
  ]
}